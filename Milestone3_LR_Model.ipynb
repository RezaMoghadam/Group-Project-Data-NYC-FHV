{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfdfb349-38d0-428e-95fe-6a6445b799ac",
   "metadata": {},
   "source": [
    "# DSC 232\n",
    "Group-Project\n",
    "\n",
    "Data: NYC FHV (Uber/Lyft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79df2e10-0aca-4f1f-9c54-1e98b4ad2d74",
   "metadata": {},
   "source": [
    "# Milestone 2\n",
    "In this milestone, the main task is to perform data exploration.\n",
    "\n",
    "For further information, please use the link for project README:\n",
    "https://github.com/RezaMoghadam/Group-Project-Data-NYC-FHV/blob/main/README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0860fdd-dd9d-4e07-81a5-4000f76d5017",
   "metadata": {},
   "source": [
    "Under this project, we are working on NYC FHV (For-Hire Vehichle) data which is a detailed record of rides in the NY city between 2019-2022. \n",
    "The businesses are Juno, Uber, Lyft, Via, and Lyft. The size of the data in zip format is about 19 GB. We are going to use San Diego Super Computer (SDSC) as a main resource to utilize spark considering the size of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81cbe7e-e935-4979-a3a7-7c714206f4c7",
   "metadata": {},
   "source": [
    "The main step is to start the Spark Session and configure the available resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9363db0-c09e-4a2e-bdc9-be73d8806521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020262ac-531f-4e59-83dc-b966d6f25841",
   "metadata": {},
   "source": [
    "Since the project files are in Parquet format, we use the appropriate app to read them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "504d6c18-8ab4-4545-aee0-ebaf8d626939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read Parquet\") \\\n",
    "    .config(\"spark.driver.memory\", \"16g\") \\\n",
    "    .config(\"spark.executor.memory\", \"40g\") \\\n",
    "    .config(\"spark.executor.instances\", 8) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "828feaa5-2831-4af5-aa4b-bcb7b50a9636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- originating_base_num: string (nullable = true)\n",
      " |-- request_datetime: timestamp_ntz (nullable = true)\n",
      " |-- on_scene_datetime: timestamp_ntz (nullable = true)\n",
      " |-- pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- trip_time: long (nullable = true)\n",
      " |-- base_passenger_fare: double (nullable = true)\n",
      " |-- tolls: double (nullable = true)\n",
      " |-- bcf: double (nullable = true)\n",
      " |-- sales_tax: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: integer (nullable = true)\n",
      " |-- tips: double (nullable = true)\n",
      " |-- driver_pay: double (nullable = true)\n",
      " |-- shared_request_flag: string (nullable = true)\n",
      " |-- shared_match_flag: string (nullable = true)\n",
      " |-- access_a_ride_flag: string (nullable = true)\n",
      " |-- wav_request_flag: string (nullable = true)\n",
      " |-- wav_match_flag: integer (nullable = true)\n",
      "\n",
      "+-----------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+----------+---------+-------------------+-----+----+---------+--------------------+-----------+----+----------+-------------------+-----------------+------------------+----------------+--------------+\n",
      "|hvfhs_license_num|dispatching_base_num|originating_base_num|   request_datetime|  on_scene_datetime|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|trip_miles|trip_time|base_passenger_fare|tolls| bcf|sales_tax|congestion_surcharge|airport_fee|tips|driver_pay|shared_request_flag|shared_match_flag|access_a_ride_flag|wav_request_flag|wav_match_flag|\n",
      "+-----------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+----------+---------+-------------------+-----+----+---------+--------------------+-----------+----+----------+-------------------+-----------------+------------------+----------------+--------------+\n",
      "|           HV0003|              B02867|              B02867|2019-02-01 00:01:26|2019-02-01 00:02:55|2019-02-01 00:05:18|2019-02-01 00:14:57|         245|         251|      2.45|      579|               9.35|  0.0|0.23|     0.83|                 0.0|       NULL| 0.0|      7.48|                  Y|                N|                 N|               N|          NULL|\n",
      "|           HV0003|              B02879|              B02879|2019-02-01 00:26:08|2019-02-01 00:41:29|2019-02-01 00:41:29|2019-02-01 00:49:39|         216|         197|      1.71|      490|               7.91|  0.0| 0.2|      0.7|                 0.0|       NULL| 2.0|      7.93|                  N|                N|                 N|               N|          NULL|\n",
      "|           HV0005|              B02510|                NULL|2019-02-01 00:48:58|               NULL|2019-02-01 00:51:34|2019-02-01 01:28:29|         261|         234|      5.01|     2159|              44.96|  0.0|1.12|     3.99|                 0.0|       NULL| 0.0|     35.97|                  N|                Y|                 N|               N|          NULL|\n",
      "|           HV0005|              B02510|                NULL|2019-02-01 00:02:15|               NULL|2019-02-01 00:03:51|2019-02-01 00:07:16|          87|          87|      0.34|      179|               7.19|  0.0|0.18|     0.64|                 0.0|       NULL| 3.0|      5.39|                  N|                Y|                 N|               N|          NULL|\n",
      "|           HV0005|              B02510|                NULL|2019-02-01 00:06:17|               NULL|2019-02-01 00:09:44|2019-02-01 00:39:56|          87|         198|      6.84|     1799|              24.25| 0.11|0.61|     2.16|                 0.0|       NULL| 4.0|     17.07|                  N|                Y|                 N|               N|          NULL|\n",
      "+-----------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+----------+---------+-------------------+-----+----+---------+--------------------+-----------+----+----------+-------------------+-----------------+------------------+----------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "\n",
    "# Read the Parquet files without specifying a schema\n",
    "df = spark.read.parquet(\"file:///expanse/lustre/projects/uci150/rmoghadam/Data/fhvhv_tripdata_*.parquet\")\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "# Show the first few rows\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6ed7cb-2918-4f62-8d20-c59141112763",
   "metadata": {},
   "source": [
    "To see the number of instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "919cffbf-3ebe-416a-ab0a-fe0314903d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "745287023"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get count to determine number of rows\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f8aac6-34d6-493e-a745-047d42feaee6",
   "metadata": {},
   "source": [
    "To see the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77c1aa64-2d92-4b84-b985-58f1132ebbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hvfhs_license_num',\n",
       " 'dispatching_base_num',\n",
       " 'originating_base_num',\n",
       " 'request_datetime',\n",
       " 'on_scene_datetime',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'trip_miles',\n",
       " 'trip_time',\n",
       " 'base_passenger_fare',\n",
       " 'tolls',\n",
       " 'bcf',\n",
       " 'sales_tax',\n",
       " 'congestion_surcharge',\n",
       " 'airport_fee',\n",
       " 'tips',\n",
       " 'driver_pay',\n",
       " 'shared_request_flag',\n",
       " 'shared_match_flag',\n",
       " 'access_a_ride_flag',\n",
       " 'wav_request_flag',\n",
       " 'wav_match_flag']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get column (parameter) names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc0c474-780c-44ce-ab79-ff906b44572d",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "\n",
    "Looking at the columns, some of them are not required for the purpose of this milestone which we drop in following step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed82ad81-29c9-4b3b-ad6c-f68fae65ca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# airport fee has erroneous data (double and integer) which makes it difficult to work with\n",
    "clean_df = df.drop(*[col for col in df.columns if col.endswith(\"_flag\")]+['airport_fee'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00483914-9f99-4d76-8b4c-8621ede666bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+----------+---------+-------------------+-----+----+---------+--------------------+----+----------+\n",
      "|hvfhs_license_num|dispatching_base_num|originating_base_num|   request_datetime|  on_scene_datetime|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|trip_miles|trip_time|base_passenger_fare|tolls| bcf|sales_tax|congestion_surcharge|tips|driver_pay|\n",
      "+-----------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+----------+---------+-------------------+-----+----+---------+--------------------+----+----------+\n",
      "|           HV0003|              B02867|              B02867|2019-02-01 00:01:26|2019-02-01 00:02:55|2019-02-01 00:05:18|2019-02-01 00:14:57|         245|         251|      2.45|      579|               9.35|  0.0|0.23|     0.83|                 0.0| 0.0|      7.48|\n",
      "|           HV0003|              B02879|              B02879|2019-02-01 00:26:08|2019-02-01 00:41:29|2019-02-01 00:41:29|2019-02-01 00:49:39|         216|         197|      1.71|      490|               7.91|  0.0| 0.2|      0.7|                 0.0| 2.0|      7.93|\n",
      "|           HV0005|              B02510|                NULL|2019-02-01 00:48:58|               NULL|2019-02-01 00:51:34|2019-02-01 01:28:29|         261|         234|      5.01|     2159|              44.96|  0.0|1.12|     3.99|                 0.0| 0.0|     35.97|\n",
      "|           HV0005|              B02510|                NULL|2019-02-01 00:02:15|               NULL|2019-02-01 00:03:51|2019-02-01 00:07:16|          87|          87|      0.34|      179|               7.19|  0.0|0.18|     0.64|                 0.0| 3.0|      5.39|\n",
      "|           HV0005|              B02510|                NULL|2019-02-01 00:06:17|               NULL|2019-02-01 00:09:44|2019-02-01 00:39:56|          87|         198|      6.84|     1799|              24.25| 0.11|0.61|     2.16|                 0.0| 4.0|     17.07|\n",
      "+-----------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+----------+---------+-------------------+-----+----+---------+--------------------+----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0133d51-adb8-4ea4-bb5d-b0fe5d60d03d",
   "metadata": {},
   "source": [
    "We pick the importnat features and remove the rows that have Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6211ecd-551c-4c33-89f2-704c966613ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_cols = [\n",
    "    \"pickup_datetime\", \"dropoff_datetime\", \"trip_miles\", \"trip_time\",\n",
    "    \"base_passenger_fare\", \"driver_pay\", \"PULocationID\", \"DOLocationID\"\n",
    "]\n",
    "\n",
    "clean_df = clean_df.dropna(subset=important_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0417582-d4fc-4f31-84a5-a078cd63dba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d9fc281-8a15-4bae-be29-79684236b7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that gets the IQR bounds per feature so that we can later remove outliers\n",
    "def IQR_bounds(df, columns):\n",
    "    quantiles = {\n",
    "        col: df.approxQuantile(col, [0.25, 0.75], 0.01)\n",
    "        for col in columns\n",
    "    }\n",
    "    bounds = {}\n",
    "    for col, (q1, q3) in quantiles.items():\n",
    "        iqr = q3 - q1\n",
    "        bounds[col] = (q1 - 1.5 * iqr, q3 + 1.5 * iqr)\n",
    "    return bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a030c762-46ed-477d-9d71-b91b58b81b0c",
   "metadata": {},
   "source": [
    "We remove the rides that have zeros under mile and fare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2d0f1e2-0859-41f9-8ec3-d94561169220",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_df.filter(\n",
    "    \"trip_miles > 0 AND trip_time > 0 AND base_passenger_fare >= 0 AND driver_pay >= 0\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92cac96d-b72b-43e1-aa8d-c65ad338eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dca74b05-0124-4906-ae3f-5cbf73106ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter out the outliers\n",
    "def filter_outliers(df, bounds):\n",
    "    condition = None\n",
    "    for col, (lower, upper) in bounds.items():\n",
    "        col_condition = (F.col(col) >= lower) & (F.col(col) <= upper)\n",
    "        condition = col_condition if condition is None else (condition & col_condition)\n",
    "    return df.filter(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7de3f202-8d19-4236-a4e4-64de2749cb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import hour, dayofweek, unix_timestamp\n",
    "\n",
    "clean_df = clean_df.withColumn(\"pickup_hour\", hour(\"pickup_datetime\"))\n",
    "clean_df = clean_df.withColumn(\"pickup_dayofweek\", dayofweek(\"pickup_datetime\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "837155eb-e8b9-4578-b331-48d26657e9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert trip_time from seconds to minutes\n",
    "clean_df = clean_df.withColumn(\"trip_time\", (col('trip_time').cast('double') / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2320043c-7d8e-496d-9e5b-01b3887846ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample ~5% of data which should be plenty to identify outlier bounds\n",
    "sample_df = clean_df.sample(fraction=0.05, seed=77).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c445e1a1-19bd-4a85-8340-ef28d3a23291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- originating_base_num: string (nullable = true)\n",
      " |-- request_datetime: timestamp_ntz (nullable = true)\n",
      " |-- on_scene_datetime: timestamp_ntz (nullable = true)\n",
      " |-- pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- trip_time: double (nullable = true)\n",
      " |-- base_passenger_fare: double (nullable = true)\n",
      " |-- tolls: double (nullable = true)\n",
      " |-- bcf: double (nullable = true)\n",
      " |-- sales_tax: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- tips: double (nullable = true)\n",
      " |-- driver_pay: double (nullable = true)\n",
      " |-- pickup_hour: integer (nullable = true)\n",
      " |-- pickup_dayofweek: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0955d739-15be-4b89-a133-7c91669f7a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+----------+------------------+-------------------+-----+----+---------+--------------------+----+----------+-----------+----------------+\n",
      "|hvfhs_license_num|dispatching_base_num|originating_base_num|   request_datetime|  on_scene_datetime|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|trip_miles|         trip_time|base_passenger_fare|tolls| bcf|sales_tax|congestion_surcharge|tips|driver_pay|pickup_hour|pickup_dayofweek|\n",
      "+-----------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+----------+------------------+-------------------+-----+----+---------+--------------------+----+----------+-----------+----------------+\n",
      "|           HV0003|              B02879|              B02879|2019-02-01 00:26:08|2019-02-01 00:41:29|2019-02-01 00:41:29|2019-02-01 00:49:39|         216|         197|      1.71| 8.166666666666666|               7.91|  0.0| 0.2|      0.7|                 0.0| 2.0|      7.93|          0|               6|\n",
      "|           HV0005|              B02510|                NULL|2019-02-01 00:06:17|               NULL|2019-02-01 00:09:44|2019-02-01 00:39:56|          87|         198|      6.84|29.983333333333334|              24.25| 0.11|0.61|     2.16|                 0.0| 4.0|     17.07|          0|               6|\n",
      "|           HV0003|              B02764|              B02764|2019-02-01 00:33:43|2019-02-01 00:36:22|2019-02-01 00:36:22|2019-02-01 00:55:30|         162|         129|      7.21|19.133333333333333|              20.69| 5.76|0.66|     2.35|                 0.0| 0.0|     23.16|          0|               6|\n",
      "|           HV0003|              B02682|              B02682|2019-02-01 00:32:37|2019-02-01 00:32:43|2019-02-01 00:35:06|2019-02-01 00:44:27|         161|         262|       2.4|              9.35|              22.16|  0.0|0.55|     1.97|                 0.0| 0.0|     16.35|          0|               6|\n",
      "|           HV0003|              B02875|              B02875|2019-02-01 00:09:32|2019-02-01 00:16:38|2019-02-01 00:17:57|2019-02-01 00:24:26|           7|           7|      0.65| 6.466666666666667|               5.21|  0.0|0.13|     0.46|                 0.0| 0.0|      3.37|          0|               6|\n",
      "+-----------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+----------+------------------+-------------------+-----+----+---------+--------------------+----+----------+-----------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38fb4f80-81db-4a10-a19f-47c2b22ddc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+--------------------+-------------------+------------------+------------------+\n",
      "|summary|       trip_miles|           trip_time|base_passenger_fare|              tips|        driver_pay|\n",
      "+-------+-----------------+--------------------+-------------------+------------------+------------------+\n",
      "|  count|         37165306|            37165306|           37165306|          37165306|          37165306|\n",
      "|   mean|4.817895814203685|  18.613717459142805|  20.08944773628104|0.7637775881624675|16.273882912479998|\n",
      "| stddev|5.556937737134216|  13.248908252754411|  17.85719415576705| 2.518739160154102|14.580484027497253|\n",
      "|    min|            0.001|0.016666666666666666|                0.0|               0.0|               0.0|\n",
      "|    25%|              1.6|   9.633333333333333|               9.17|               0.0|              7.38|\n",
      "|    50%|             2.95|                15.2|              14.96|               0.0|             12.25|\n",
      "|    75%|             5.91|               23.75|              24.83|               0.0|             20.47|\n",
      "|    max|           616.81|              1364.0|             3356.7|             500.0|           1907.65|\n",
      "+-------+-----------------+--------------------+-------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_df.select('trip_miles','trip_time','base_passenger_fare','tips','driver_pay').summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cce9cb9-abc2-461d-804d-a95547980d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_cols = ['trip_miles','trip_time','base_passenger_fare','tips','driver_pay']\n",
    "\n",
    "# Get bounds from sample\n",
    "bounds = IQR_bounds(sample_df, outlier_cols)\n",
    "\n",
    "# Filter full DataFrame using precomputed bounds\n",
    "clean_df = filter_outliers(clean_df, bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6261b281-73d7-4a98-a28c-4c19bb08a62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------+-------------------+---------+------------------+\n",
      "|summary|        trip_miles|           trip_time|base_passenger_fare|     tips|        driver_pay|\n",
      "+-------+------------------+--------------------+-------------------+---------+------------------+\n",
      "|  count|         564504692|           564504692|          564504692|564504692|         564504692|\n",
      "|   mean|3.4100701813600103|  15.416330477081727|  15.46235074317146|      0.0|12.471303166171596|\n",
      "| stddev|2.5675978938641495|   8.383267618623808|  8.789845428331509|      0.0|7.4588581050483835|\n",
      "|    min|             0.001|0.016666666666666666|                0.0|      0.0|               0.0|\n",
      "|    25%|              1.49|   8.983333333333333|               8.54|      0.0|              6.83|\n",
      "|    50%|              2.57|  13.733333333333333|              13.22|      0.0|             10.85|\n",
      "|    75%|               4.6|  20.233333333333334|              20.49|      0.0|              16.9|\n",
      "|    max|            12.192|   44.56666666666667|              47.94|      0.0|             39.66|\n",
      "+-------+------------------+--------------------+-------------------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_df.select('trip_miles','trip_time','base_passenger_fare','tips','driver_pay').summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed23f652-0eb6-4dd6-b23e-70edd84b45e7",
   "metadata": {},
   "source": [
    "Tips does not seem to contribute and is inconsistent. Though it does contribute some variance to driver pay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15141de2-c607-4f4d-a6fd-6472012895e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns one hot vectors and encode\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "cat_cols = ['pickup_hour', 'pickup_dayofweek', 'hvfhs_license_num']\n",
    "num_cols = ['trip_miles', 'trip_time', 'base_passenger_fare']\n",
    "\n",
    "index_output = [f\"{col}_idx\" for col in cat_cols]\n",
    "ohe_output = [f\"{col}_vec\" for col in cat_cols]\n",
    "\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=idx_col, handleInvalid=\"keep\") \n",
    "            for col, idx_col in zip(cat_cols, index_output)]\n",
    "\n",
    "encoders = [OneHotEncoder(inputCol=idx_col, outputCol=ohe_col) \n",
    "            for idx_col, ohe_col in zip(index_output, ohe_output)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b026933-ab87-4740-84ca-2b3ba8eb8193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "\n",
    "# Assemble numerical features \n",
    "num_assembler = VectorAssembler(inputCols=num_cols, outputCol=\"numerical_features\")\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler(inputCol=\"numerical_features\", outputCol=\"scaled_numerical\", withMean=True, withStd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a5572ac-cbb1-4532-955f-4ef4aa4f7a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final assembler combines scaled numeric + encoded categoricals\n",
    "final_assembler = VectorAssembler(\n",
    "    inputCols=[\"scaled_numerical\"] + ohe_output,\n",
    "    outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9c59ff7-53b9-4e09-a8f5-2130c30165c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"driver_pay\")\n",
    "\n",
    "# Combine all stages into a pipeline\n",
    "pipeline = Pipeline(stages=indexers + encoders + [num_assembler, scaler, final_assembler, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e413ef9-3954-4ff8-832a-a1a3b32f1cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = clean_df.sample(fraction=0.05, seed=77).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2384d787-f4c1-4e93-bdd5-fac438ea0746",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = sample_df.randomSplit([0.8, 0.2], seed=77)\n",
    "\n",
    "# Fit on training data\n",
    "model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba55d514-a033-4874-a80e-bb8170bbf9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply on test data\n",
    "predictions = model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58a1defb-c0d4-45a8-8808-446cc8aa4a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 3.316885915662238\n",
      "Test R2: 0.802147836614175\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"driver_pay\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "r2 = RegressionEvaluator(labelCol=\"driver_pay\", predictionCol=\"prediction\", metricName=\"r2\").evaluate(predictions)\n",
    "\n",
    "print(f\"Test RMSE: {rmse}\")\n",
    "print(f\"Test R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "192046e1-9242-4da6-8701-aba6e66ce27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7959307586796331,1.9080805547537982,4.311907524232596,0.07594437493418801,0.08458518665368274,0.015299239553914205,-0.0009098122422828767,-0.02164182590774889,0.06634783567912789,-0.09423675640395227,-0.0748394050170997,0.1840458363478264,-0.06794393512156578,0.07295417650064831,-0.12171886650958018,-0.07029059258268763,-0.1548807227093385,-0.1837783308433386,-0.18949845552948721,0.142169583661868,0.1468826495944675,0.02980786165336191,0.037797666735403544,0.039193376515460766,0.027739086396776164,0.03769618462880951,0.17815311035768952,0.028317517687953757,0.04234165389312263,0.021951220346495333,-0.008220653115877177,-0.054280699367565105,-0.05381081396370745,0.008565442219794538,1.3987934081896172,-0.6578342117267973,-8.460441690774871,1.4598821754324158]\n"
     ]
    }
   ],
   "source": [
    "lr_model = model.stages[-1]  # Get the final stage\n",
    "print(lr_model.coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51713818-9e68-49ae-ad20-294650386645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled_trip_miles                  : 0.7959\n",
      "scaled_trip_time                   : 1.9081\n",
      "scaled_base_passenger_fare         : 4.3119\n",
      "pickup_hour_vec_0                  : 0.0759\n",
      "pickup_hour_vec_1                  : 0.0846\n",
      "pickup_hour_vec_2                  : 0.0153\n",
      "pickup_hour_vec_3                  : -0.0009\n",
      "pickup_hour_vec_4                  : -0.0216\n",
      "pickup_hour_vec_5                  : 0.0663\n",
      "pickup_hour_vec_6                  : -0.0942\n",
      "pickup_hour_vec_7                  : -0.0748\n",
      "pickup_hour_vec_8                  : 0.1840\n",
      "pickup_hour_vec_9                  : -0.0679\n",
      "pickup_hour_vec_10                 : 0.0730\n",
      "pickup_hour_vec_11                 : -0.1217\n",
      "pickup_hour_vec_12                 : -0.0703\n",
      "pickup_hour_vec_13                 : -0.1549\n",
      "pickup_hour_vec_14                 : -0.1838\n",
      "pickup_hour_vec_15                 : -0.1895\n",
      "pickup_hour_vec_16                 : 0.1422\n",
      "pickup_hour_vec_17                 : 0.1469\n",
      "pickup_hour_vec_18                 : 0.0298\n",
      "pickup_hour_vec_19                 : 0.0378\n",
      "pickup_hour_vec_20                 : 0.0392\n",
      "pickup_hour_vec_21                 : 0.0277\n",
      "pickup_hour_vec_22                 : 0.0377\n",
      "pickup_dayofweek_vec_0             : 0.1782\n",
      "pickup_dayofweek_vec_1             : 0.0283\n",
      "pickup_dayofweek_vec_2             : 0.0423\n",
      "pickup_dayofweek_vec_3             : 0.0220\n",
      "pickup_dayofweek_vec_4             : -0.0082\n",
      "pickup_dayofweek_vec_5             : -0.0543\n",
      "hvfhs_license_num_vec_0            : -0.0538\n",
      "hvfhs_license_num_vec_1            : 0.0086\n",
      "hvfhs_license_num_vec_2            : 1.3988\n",
      "hvfhs_license_num_vec_3            : -0.6578\n",
      "hvfhs_license_num_vec_4            : -8.4604\n"
     ]
    }
   ],
   "source": [
    "# Manually build feature names\n",
    "numeric_features = ['scaled_' + col for col in num_cols]\n",
    "pickup_hour_features = [f'pickup_hour_vec_{i}' for i in range(23)]\n",
    "pickup_day_features = [f'pickup_dayofweek_vec_{i}' for i in range(6)]\n",
    "hvfhs_license_features = [f'hvfhs_license_num_vec_{i}' for i in range(5)]\n",
    "\n",
    "all_features = numeric_features + pickup_hour_features + pickup_day_features + hvfhs_license_features\n",
    "\n",
    "# Print nicely\n",
    "for name, coef in zip(all_features, lr_model.coefficients):\n",
    "    print(f\"{name:35s}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5faeec-42e0-4f3b-9267-48f33509de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_df.write.mode(\"overwrite\").parquet(\"/path/to/clean_data\")\n",
    "# lr_model.save(\"/path/to/linear_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c114ad-5533-4ca0-b818-1eb22c485b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_df.select(\n",
    "#     F.mean(\"driver_pay\").alias(\"mean\"),\n",
    "#     F.min(\"driver_pay\").alias(\"min\"),\n",
    "#     F.max(\"driver_pay\").alias(\"max\"),\n",
    "#     F.stddev(\"driver_pay\").alias(\"stddev\")\n",
    "# ).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e8d401-272c-44be-ba48-f97300a011aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
